# Projet de Séries temporelles linéaires - 2A ENSAE

## Partie I : Données et stationnarisation

### Q1 - Présentation de la série

``` {r import packages}

# on utilise "zoo" pour formaliser les séries temporelles
#install.packages("zoo")
require(zoo)

# on utilise "tseries" pour diverses fonctions
#install.packages("tseries")
require(tseries)

# on utilise "fUnitRoots" pour les tests de racine unitaire
#install.packages("fUnitRoots")
library(fUnitRoots)

# on utilise "forecast" pour les prédictions
#install.packages("forecast")
require("forecast")
```

Link : https://www.insee.fr/fr/statistiques/serie/010537434

``` {r import dataset}
datafile <- "engrais_valeurs_mensuelles.csv"
data <- read.csv(datafile, sep=";")
```

On exhibe la date de début et la date de fin de la série temporelle pour ajuster nos dates.

``` {r create dates}
string_dates <- as.character(data$dates)
# premiere et la derniere date pour définir les indices des dates
string_dates[1]; string_dates[length(string_dates)]
# on définit les dates de la série
dates <- as.yearmon(seq(from=1990+1/12, to=2022+3/12, by=1/12))
```

La série étant transposée, on applique l'opérateur "rev".
On retire les six dernières données afin de pouvoir tester les performances de nos différents modèles (en particulier avec le score RMSE).

``` {r create ts fertilizer and dfertilizer with zoo}
# on permute la série sinon elle n'est pas dans le bon sens
fertilizer.source <- zoo(rev(data$indices), order.by=dates)
# on enlève les 6 dernières dates à la série en niveau serie
# cela permettra de tester avec le RMSE les différents modèles concurrents
fertilizer <- fertilizer.source[1:(length(fertilizer.source)-6)]
# delec est la série en différence première
dfertilizer.source <- diff(fertilizer.source, 1)
dfertilizer <- diff(fertilizer, 1)
```

```{r plot and decompose fertilizer.source}
plot(fertilizer.source, type="l", lwd=1, col="blue", main="fabrication d'engrais et produits azotés", xlab="dates", ylab="values")
decompose_fertilizer.source <- decompose(fertilizer.source)
plot(decompose_fertilizer.source, col="blue", xlab="dates")
```

### Q2 - Stationnarisation de la série

On constate sur le graphique ci-dessus une tendance linéaire positive pour la série en niveau.

On vérifie d'abord la tendance linéaire en effectuant une régression linéaire des valeurs de la série tronquée sur les dates.

```{r lm}
truncated_dates <- dates[1:(length(fertilizer.source)-6)]
fertilizer <- fertilizer.source[1:(length(fertilizer.source)-6)]
summary(lm(fertilizer ~ truncated_dates))
```

Cette régression linéaire confirme la présence d'une tendance linéaire négative dans nos données et d'une constante : p_values < 1 %.

On cherche à déterminer si la série est stationnaire ou non. Pour cela, on réalise un test de racine unitaire ADF dont l'hypothèse H1 est la stationnarité de la série. On effectue bien le test ADF dans le cas avec constante et tendance.

```{r fertilizer adf test}
# test ADF dans le cas avec constante et tendance
adf_fertilizer <- adfTest(fertilizer, lag=0, type="ct")
adf_fertilizer
```

D'après le test ADF, la série en niveau est stationnaire. Seulement, pour que le test soit valide, il faut que les résidus de la régression ne soient pas autocorrélés.
On teste donc l’autocorrélation des résidus dans la régression sur une période de deux ans.

``` {r test residuals autocorrelation : cf. TD4}

Qtests <- function(series, k, fitdf=0){
  pvals <- apply(matrix(1:k), 1, FUN=function(l){
  pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
  return(c("lag"=l,"pval"=pval))
  })
  return(t(pvals))
}

Qtests(adf_fertilizer@test$lm$residuals, 24, length(adf_fertilizer@test$lm$coefficients))
```

L’absence d’autocorrélation des résidus est rejetée, le test ADF avec aucun
retard n’est donc pas valide. On ajoute alors des retards jusqu’à ce que les résidus ne soient plus autocorrélés à l'aide de la fonction ci-dessous.

```{r fertilizer adf test : cf. TD5}
adfTest_valid <- function(series,kmax,type){ 
# tests ADF jusqu’à des résidus non autocorrélés
k <- 0
noautocorr <- 0
while (noautocorr==0){
cat(paste0("ADF with ",k, " lags: residuals OK? "))
adf <- adfTest(series,lags=k,type=type)
pvals <- Qtests(adf@test$lm$residuals,24,fitdf=length(adf@test$lm$coefficients))[,2]
if (sum(pvals<0.05,na.rm=T) == 0) {
noautocorr <- 1; cat("OK \n")}
else cat("nope \n")
k <- k + 1
}
return(adf)
}

adf <- adfTest_valid(fertilizer, 24, "ct")
adf
```

Avec six retards, les résidus ne sont plus autocorrélés. On constate alors que la série en niveau n'est pas stationnaire : le test ADF ne rejette pas l'hypothèse racine unitaire (p-value > 0.05) i.e. de non stationnarité de la série. 
On passe à la série en différence première ou intégrée d'ordre 1.

```{r dfertilizer adf test}
# création et représentation de dfertilizer
dfertilizer.source <- diff(fertilizer.source, 1)
dfertilizer <- diff(fertilizer, 1)
plot(dfertilizer.source, type="l", lwd=1, col="blue", main="série différenciée à l'ordre 1", xlab="dates", ylab="values")

# il n'y a pas de tendance ni de constante
summary(lm(dfertilizer ~ dates[2:(length(fertilizer.source)-6)]))

# test DF
adf_dfertilizer <- adfTest(dfertilizer, lag=0, type="nc")
adf_dfertilizer

# autocorrélation des résidus
Qtests(adf_dfertilizer@test$lm$residuals, 24, length(adf_dfertilizer@test$lm$coefficients))
```

Non seulement, la série intégrée d'ordre 1 ne présente pas de tendance et de constante significative (p-valeurs > 0.7) mais en plus elle vérifie l’absence autocorrélation des résidus ce qui permet d'effectuer le test de Dickey Fuller.

```{r dfertilizer adf test}
adf <- adfTest_valid(dfertilizer, 24, "nc")
adf
```

Le test ADF n'est pas rejeté avec cinq retards pour la série différenciée, on retient son hypothèse alternative : la série est stationnaire. 

On détermine désormais pmax et qmax pour évaluer le modèle ARIMA(p,1,q) adéquat.

### Q3 - Représentation de la série avant et après transformation

``` {r plot fertilizer and dfertilizer}
plot(cbind(fertilizer.source,dfertilizer.source), type="l", lwd=1, col="blue", main="séries en niveau (haut) et intégrée à l'ordre 1 (bas)", xlab="dates", ylab="values")
```

## Partie 2 : Modèles ARMA

### Q4 - Choix du modèle ARMA

On détermine d'abord pmax et qmax.

``` {r acf and pacf dfertilizer}
acf(dfertilizer)
pacf(dfertilizer)
```

On ignore les autocorrélations (partielles) pour les retards supérieurs strictement à 15 dans l'objectif d'obtenir un modèle raisonnablement simplifié.
Dans notre cas, il n'y en a pas quand bien même on note la présence d'autocorrélations persistantes mais non significatives tous les six mois.

``` {r pmax and qmax}
pmax=6; qmax=7
```



``` {r find valid models}

# fonction de test des significativités individuelles des coefficients
signif <- function(estim){
  coef <- estim$coef
  se <- sqrt(diag(estim$var.coef))
  t <- coef/se
  pval <- (1-pnorm(abs(t)))*2
  return(rbind(coef,se,pval))
}

# fonction pour estimer un arima et en vérifier l’ajustement et la validité
modelchoice <- function(p, q, data=dfertilizer, k=24){
  estim <- try(arima(data, c(p,0,q),optim.control=list(maxit=20000)))
  if (class(estim)=="try-error") return(c("p"=p,"q"=q,"arsignif"=NA,"masignif"=NA,"resnocorr"=NA, "ok"=NA))
  arsignif <- if (p==0) NA else signif(estim)[3,p]<=0.05
  masignif <- if (q==0) NA else signif(estim)[3,p+q]<=0.05
  resnocorr <- sum(Qtests(estim$residuals,24,length(estim$coef)-1)[,2]<=0.05,na.rm=T)==0
  checks <- c(arsignif,masignif,resnocorr)
  ok <- as.numeric(sum(checks,na.rm=T)==(3-sum(is.na(checks))))
  return(c("p"=p,"q"=q,"arsignif"=arsignif,"masignif"=masignif,"resnocorr"=resnocorr,"ok"=ok))
}


# fonction pour estimer et vérifier tous les arma(p,q) (p<=pmax ; q<=qmax)
armamodelchoice <- function(pmax,qmax){
  pqs <- expand.grid(0:pmax,0:qmax) ; t(apply(matrix(1:dim(pqs)[1]),1,function(row) {
    p <- pqs[row,1]; q <- pqs[row,2]
    cat(paste0("Computing ARMA(",p,",",q,") \n"))
    modelchoice(p,q)
  }))}

armamodels <- armamodelchoice(pmax,qmax)

# on ne retient que les modèles ajustés et valides
selec <- armamodels[armamodels[, "ok"]==1&!is.na(armamodels[, "ok"]),]
selec
```

On obtient 5 modèles valides et justifiés. On évalue la qualité de ces modèles avec les critères AIC et BIC.

``` {r AIC and BIC}

# on crée la liste des arma(p,q) possibles
pqs <- apply(selec,1,function(row)
list("p"=as.numeric(row[1]), "q"=as.numeric(row[2])))
names(pqs) <- paste0("arma(", selec[,1], ",", selec[,2],")")

# on crée la liste des modèles arma(p,q)
models <- lapply(pqs, function(pq) arima(dfertilizer, c(pq[["p"]], 0, pq[["q"]])))

# on calcule les AIC et BIC des modèles possibles
vapply(models, FUN.VALUE=numeric(2), function(m) c("AIC"=AIC(m),"BIC"=BIC(m)))
```

On compare les prédictions des modèles arima(2,1,1) (minimise l'AIC) et arma(6,1,7) (minimise le BIC) avec le RMSE (Root Mean Squared Error).

``` {r select model with best rmse}

# définition des deux modèles concurrents
ar6ma7 <- arima(fertilizer, c(6,1,7), include.mean=F)
ar2ma1 <- arima(fertilizer, c(2,1,1), include.mean=F)

# on crée des séries pour les prédictions des deux modèles à tester
models <- c("ar6ma7","ar2ma1")
preds <- zoo(matrix(NA, ncol=2, nrow=6), order.by=tail(index(fertilizer.source), 6))
colnames(preds) <- models
fertilizerp <- preds

# on remplit la série avec les prédictions des modèles
for (model in models){
pred <- zoo(predict(get(model), 6)$pred, order.by=tail(index(fertilizer.source), 6))
fertilizerp[, model] <- pred
}

# on affiche les valeurs observées et les prédictions
obs <- tail(fertilizer.source, 6)
cbind(obs, fertilizerp)

# on calcule les rmse
apply(fertilizerp, 2, function(x) sqrt(sum((x-obs)^2)/6)/sd(fertilizer.source))
```

### Q5 - Expression du modèle ARIMA retenu.

``` {r selected model}
selected_model <- ar2ma1
selected_model
```

On vérifie la significativité du coefficient.

``` {r check selected model}

# test de significativité des coefficients
tar2ma1 <- ar2ma1$coef / sqrt(diag(ar2ma1$var.coef))
pvar2ma1 <- (1-pnorm(abs(tar2ma1)))*2
pvar2ma1["ma1"]
pvar2ma1["ar2"]

# test de non auto-corrélation des résidus
Qtests(ar2ma1$residuals, 24, fitdf=1)

```

## Partie III : Prévisions

### Q6 - Région de confiance pour les valeurs futures t+1 et t+2

Voir le rapport PDF.

### Q7 - Hypothèses pour la région de confiance

Voir le rapport PDF.

### Q8 - Représentation graphique de la région de confiance

On réalise les prédictions pour les mois d'octobre et novembre 2021. Les zones en gris clair représentent les intervalles de confiance à 95% et les points rouges les prédictions.

``` {r forecasts}
forecasts <- forecast(ar1ma1, h=6, level=0.95)
plot(forecasts, xlim=c(2018,2022), shadecols = "grey", fcol="red", main = "intervalles de confiance (alpha = 0.95) pour T+1 à T+6")
par(new=T)
plot(fertilizer.source, type="l", lwd=1, col="blue", xlim=c(2018,2022))
```

Les prédictions ne sont pas excellentes mais ont le mérite de suivre une tendance haussière conformément à la réalité.

### Q9 - Question ouverte

Voir le rapport PDF.


